#!/usr/bin/python3.6

#################################################################
# Import utils directory
import sys
import os
from os import path
import pathlib
main_dir = pathlib.Path(__file__).parent.parent.parent.absolute()
sys.path.append(str(main_dir))


################################################################

import argparse
import itertools
import statistics
from PIL import Image


import torchvision
import torchvision.transforms as transforms
from torch.utils.data import DataLoader
from torch.autograd import Variable

import torch
import tqdm
import lpips
import matplotlib.pylab as plot


from RGB2TIR.utils.models import Generator
from RGB2TIR.utils.models import Discriminator
from RGB2TIR.utils.utils import ReplayBuffer
from RGB2TIR.utils.utils import LambdaLR
from RGB2TIR.utils.vgg_loss import PerceptualLoss
# from RGB2TIR.utils.utils import Logger
from RGB2TIR.utils.utils import weights_init_normal
from RGB2TIR.utils.utils import ssim as criterion_ssim
from RGB2TIR.utils.datasets import ImageDataset
from RGB2TIR.utils.datasets import shuffle_data
from RGB2TIR.utils.datasets import get_list_of_files



parser = argparse.ArgumentParser()
parser.add_argument('--epoch',       type=int,   default=0,    help='starting epoch')
parser.add_argument('--n_epochs',    type=int,   default=100,  help='number of epochs of training')
parser.add_argument('--batchSize',   type=int,   default=1,    help='size of the batches')
parser.add_argument('--lr',          type=float, default=0.005, help='initial learning rate')
parser.add_argument('--decay_epoch', type=int,   default=20,   help='epoch to start linearly decaying the learning rate to 0')
parser.add_argument('--size',        type=int,   default=256,  help='size of the data crop (squared assumed)')
parser.add_argument('--TIR_w',       type=int,   default=640,  help='size of the data TIR width (squared assumed)')
parser.add_argument('--TIR_h',       type=int,   default=480,  help='size of the data crop (squared assumed)')
parser.add_argument('--RGB_w',       type=int,   default=1280, help='size of the data TIR width (squared assumed)')
parser.add_argument('--RGB_h',       type=int,   default=960,  help='size of the data crop (squared assumed)')
parser.add_argument('--input_nc',    type=int,   default=1,    help='number of channels of input data')
parser.add_argument('--output_nc',   type=int,   default=3,    help='number of channels of output data')
parser.add_argument('--cuda',        action='store_true',      help='use GPU computation')
parser.add_argument('--n_cpu',       type=int,   default=8,    help='number of cpu threads to use during batch generation')
parser.add_argument('--sd',          action='store_true',      help='shuffle data for test and train')
parser.add_argument('--nr',          action='store_true',      help='don\'t run the network')
parser.add_argument('--create_new_net', action='store_true',   help='create new network, and don\'t work with old one')
parser.add_argument('--generator_TIR_2_RGB', type=str, default='RGB2TIR/output/p_netG_TIR_2_RGB.pth', help='TIR_2_RGB generator checkpoint file')
parser.add_argument('--generator_RGB_2_TIR', type=str, default='RGB2TIR/output/p_netG_RGB_2_TIR.pth', help='RGB_2_TIR generator checkpoint file')
parser.add_argument('--discriminator_TIR', type=str, default='RGB2TIR/output/p_netD_TIR.pth', help='TIR discriminator checkpoint file')
parser.add_argument('--discriminator_RGB', type=str, default='RGB2TIR/output/p_netD_RGB.pth', help='RGB discriminator checkpoint file')
opt = parser.parse_args()
print(opt)

if torch.cuda.is_available() and not opt.cuda:
    print("WARNING: You have a CUDA device, so you should probably run with --cuda")

###### shuffle data ######
if opt.sd:
    shuffle_data()
    
###### Definition of variables ######
# Networks
# vgg19_critertion = torchvision.models.vgg19_bn(pretrained=True)
vgg19_criterion = PerceptualLoss(features_to_compute=['conv5_4'], criterion=torch.nn.L1Loss(), shave_edge=None)
criterion_lpips = lpips.LPIPS(net='alex',version=0.1)


netG_TIR_2_RGB = Generator(opt.input_nc, opt.output_nc, input_type="TIR")
netG_RGB_2_TIR = Generator(opt.output_nc, opt.input_nc, input_type="RGB")
netD_TIR = Discriminator(opt.input_nc, input_type="TIR")
netD_RGB = Discriminator(opt.output_nc, input_type="RGB")

if opt.cuda:
    vgg19_criterion.cuda()
    criterion_lpips.cuda()
    netG_TIR_2_RGB.cuda()
    netG_RGB_2_TIR.cuda()
    netD_TIR.cuda()
    netD_RGB.cuda()

if os.path.exists(os.path.join(main_dir, opt.generator_TIR_2_RGB)) and not opt.create_new_net: # load pre trained networks
    print("Loading exists nets...")
    netG_TIR_2_RGB.load_state_dict(torch.load(os.path.join(main_dir, opt.generator_TIR_2_RGB)))
    netG_RGB_2_TIR.load_state_dict(torch.load(os.path.join(main_dir, opt.generator_RGB_2_TIR)))
    netD_TIR.load_state_dict(torch.load(os.path.join(main_dir, opt.discriminator_TIR)))
    netD_RGB.load_state_dict(torch.load(os.path.join(main_dir, opt.discriminator_RGB)))

else:
    netG_TIR_2_RGB.apply(weights_init_normal)
    netG_RGB_2_TIR.apply(weights_init_normal)
    netD_TIR.apply(weights_init_normal)
    netD_RGB.apply(weights_init_normal)

# Lossess
criterion_MSE = torch.nn.MSELoss()
criterion_L1  = torch.nn.L1Loss()


# Optimizers & LR schedulers
optimizer_G = torch.optim.Adam(itertools.chain(netG_TIR_2_RGB.parameters(), netG_RGB_2_TIR.parameters()),
                                lr=opt.lr, betas=(0.5, 0.999))
optimizer_D_TIR = torch.optim.Adam(netD_TIR.parameters(), lr=opt.lr, betas=(0.5, 0.999))
optimizer_D_RGB = torch.optim.Adam(netD_RGB.parameters(), lr=opt.lr, betas=(0.5, 0.999))

lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)
lr_scheduler_D_TIR = torch.optim.lr_scheduler.LambdaLR(optimizer_D_TIR, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)
lr_scheduler_D_RGB = torch.optim.lr_scheduler.LambdaLR(optimizer_D_RGB, lr_lambda=LambdaLR(opt.n_epochs, opt.epoch, opt.decay_epoch).step)


# Inputs & targets memory allocation
Tensor = torch.cuda.FloatTensor if opt.cuda else torch.Tensor
input_TIR = Tensor(opt.batchSize, opt.input_nc, opt.TIR_w, opt.TIR_h)
input_RGB = Tensor(opt.batchSize, opt.output_nc, opt.RGB_w, opt.RGB_h)
target_real = Variable(Tensor(opt.batchSize).fill_(1.0), requires_grad=False)
target_fake = Variable(Tensor(opt.batchSize).fill_(0.0), requires_grad=False)

fake_TIR_buffer = ReplayBuffer()
fake_RGB_buffer = ReplayBuffer()

# Dataset loader
TIR_transforms_ = [transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize((0.5,), (0.5,))]
RGB_transforms_ = [transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]
dataloader = DataLoader(ImageDataset(TIR_transforms_=TIR_transforms_, RGB_transforms_=TIR_transforms_, unaligned=True),
                        batch_size=opt.batchSize, shuffle=True, num_workers=0)

# Loss plot
#logger = Logger(opt.n_epochs, len(dataloader))
###################################

mean_Gan_loss       = []
mean_Generate_loss  = []
mean_Recovered_loss = []
mean_Ssim_loss      = []
mean_Lpips_f_loss   = []
mean_Vgg_loss       = []
# pred_real_l, pred_fake_l = [], []

###### Training ######
final_list = get_list_of_files()

if opt.nr:
    print(f"'no run' flag was inserted. {len(final_list)} files were submitted")
    exit(1)


print('#########################################')
print('train')
print('=====')
print('Starting Pre Train For Discriminators')
for i, batch in enumerate(dataloader):
    if i == 50:
        break

    item_RGB = batch['RGB'][:, :, 113:1393, 33:993]

    real_TIR = Variable(input_TIR.copy_(batch['TIR'][0, :, :, :]))
    real_RGB = Variable(input_RGB.copy_(item_RGB[0, :, :, :]))

    fake_RGB = netG_TIR_2_RGB(real_TIR)
    fake_TIR = netG_RGB_2_TIR(real_RGB)


    optimizer_D_TIR.zero_grad()

    # Real loss
    pred_real = netD_TIR(real_TIR)
    loss_D_real = criterion_MSE(pred_real[0, :], target_real)

    # Fake loss
    fake_TIR = fake_TIR_buffer.push_and_pop(fake_TIR)
    pred_fake = netD_TIR(fake_TIR.detach())
    loss_D_fake = criterion_MSE(pred_fake[0, :], target_fake)

    # Total loss
    loss_D_TIR = (loss_D_real + loss_D_fake) * 0.5
    loss_D_TIR.backward()

    optimizer_D_TIR.step()
    ###################################

    ###### Discriminator RGB ######
    optimizer_D_RGB.zero_grad()

    # Real loss
    pred_real = netD_RGB(real_RGB)
    loss_D_real = criterion_MSE(pred_real[0, :], target_real)

    # Fake loss
    fake_RGB = fake_RGB_buffer.push_and_pop(fake_RGB)
    pred_fake = netD_RGB(fake_RGB.detach())
    loss_D_fake = criterion_MSE(pred_fake[0, :], target_fake)

    # Total loss
    loss_D_RGB = (loss_D_real + loss_D_fake) * 0.5
    loss_D_RGB.backward()

    optimizer_D_RGB.step()

print('Starting Pre Train For Generators')
for i, batch in enumerate(dataloader):
    if i == 100:
        break
    item_RGB = batch['RGB'][:, :, 113:1393, 33:993]

    real_TIR = Variable(input_TIR.copy_(batch['TIR'][0, :, :, :]))
    real_RGB = Variable(input_RGB.copy_(item_RGB[0, :, :, :]))

    ###### Generators TIR_2_RGB and RGB_2_TIR ######
    optimizer_G.zero_grad()

    # GAN loss
    fake_RGB = netG_TIR_2_RGB(real_TIR)
    fake_TIR = netG_RGB_2_TIR(real_RGB)

    # Fake vs. Real Loss
    loss_TIR_Generate = criterion_L1(fake_TIR, real_TIR) * 2.1
    loss_RGB_Generate = criterion_L1(fake_RGB, real_RGB) * 2.2

    # Cycle loss
    recovered_TIR = netG_RGB_2_TIR(fake_RGB)
    loss_cycle_ABA = criterion_L1(recovered_TIR, real_TIR)

    recovered_RGB = netG_TIR_2_RGB(fake_TIR)
    loss_cycle_BAB = criterion_L1(recovered_RGB, real_RGB)

    # VGG loss
    loss_vgg_TIR = vgg19_criterion(recovered_TIR, real_TIR)
    loss_vgg_RGB = vgg19_criterion(recovered_RGB, real_RGB)

    # Total loss
    total_loss_Generate = loss_TIR_Generate + loss_RGB_Generate
    total_loss_cycle = loss_cycle_ABA + loss_cycle_BAB
    total_loss_vgg = loss_vgg_TIR + loss_vgg_RGB

    loss_G = total_loss_Generate + total_loss_cycle + total_loss_vgg
    loss_G.backward()
    optimizer_G.step()

print("Finished Pre-Training")

print(f"Starting train. {opt.n_epochs} epoches will be ran, {len(dataloader)} files for each epoch\n")
for ep in range(opt.n_epochs):
    sys.stdout.write(f"\r\repoch number {ep + 1}/{opt.n_epochs} - {(ep + 1) * 100 /opt.n_epochs}%")
    print()
    Gan_loss        = []
    Generate_loss   = []
    Recovered_loss  = []
    # Ssim_loss       = []
    # lpips_fake_loss = []
    Vgg_loss        = []
    pred_real_l, pred_fake_l = [], []

    for i, batch in tqdm.tqdm(enumerate(dataloader), total=len(dataloader), leave=False):
        # sys.stdout.write(f"\rfile number {i}/{len(dataloader)} - {i * 100 /len(dataloader) :.2f}%")

        item_RGB = batch['RGB'][:,:,113:1393, 33:993]

        real_TIR = Variable(input_TIR.copy_(batch['TIR'][0, :, :, :]))
        real_RGB = Variable(input_RGB.copy_(item_RGB[0, :, :, :]))

        ###### Generators TIR_2_RGB and RGB_2_TIR ######
        optimizer_G.zero_grad()

        # GAN loss
        fake_RGB = netG_TIR_2_RGB(real_TIR)
        pred_fake = netD_RGB(fake_RGB)
        loss_GAN_TIR_2_RGB = criterion_MSE(pred_fake[0, :], target_real) * 1.4
        Gan_loss.append(loss_GAN_TIR_2_RGB.item())


        fake_TIR = netG_RGB_2_TIR(real_RGB)
        pred_fake = netD_TIR(fake_TIR)
        loss_GAN_RGB_2_TIR = criterion_MSE(pred_fake[0, :], target_real) * 1.3

        # Fake vs. Real Loss
        loss_TIR_Generate = criterion_L1(fake_TIR, real_TIR) * 1.8
        loss_RGB_Generate = criterion_L1(fake_RGB, real_RGB) * 2.2
        Generate_loss.append(loss_RGB_Generate.item())

        # Cycle loss
        recovered_TIR = netG_RGB_2_TIR(fake_RGB)
        loss_cycle_ABA = criterion_L1(recovered_TIR, real_TIR)
        Recovered_loss.append(loss_cycle_ABA.item())

        recovered_RGB = netG_TIR_2_RGB(fake_TIR)
        loss_cycle_BAB = criterion_L1(recovered_RGB, real_RGB)


        # SSIM loss
        # loss_ssim_ABA = (1 - criterion_ssim(recovered_TIR, real_TIR))
        # loss_ssim_BAB = (1 - criterion_ssim(recovered_RGB, real_RGB))
        # Ssim_loss.append(loss_ssim_ABA.item())

        # LPIPS loss
        # loss_lpips_fake      = criterion_lpips.forward(fake_RGB, real_RGB)[0, 0, 0, 0]
        # loss_lpips_recovered = criterion_lpips.forward(recovered_RGB, real_RGB)[0, 0, 0, 0]
        # lpips_fake_loss.append(loss_lpips_fake.item())

        # VGG loss
        loss_vgg_TIR = vgg19_criterion(recovered_TIR, real_TIR)
        loss_vgg_RGB = vgg19_criterion(recovered_RGB, real_RGB)
        Vgg_loss.append(loss_vgg_RGB.item())

        # Total loss
        total_loss_GAN      = loss_GAN_TIR_2_RGB + loss_GAN_RGB_2_TIR
        total_loss_Generate = loss_TIR_Generate + loss_RGB_Generate
        total_loss_cycle    = loss_cycle_ABA + loss_cycle_BAB
        # total_loss_ssim = loss_ssim_BAB + loss_ssim_ABA
        total_loss_vgg      = loss_vgg_TIR + loss_vgg_RGB
        # total_loss_lpips    = loss_lpips_fake + loss_lpips_recovered

        # loss_G = total_loss_GAN + total_loss_Generate + total_loss_cycle + total_loss_ssim + total_loss_lpips
        loss_G = total_loss_GAN + total_loss_Generate + total_loss_cycle + total_loss_vgg
        loss_G.backward()
        
        optimizer_G.step()
        ###################################



        ###### Discriminator TIR ######
        optimizer_D_TIR.zero_grad()

        # Real loss
        pred_real = netD_TIR(real_TIR)
        loss_D_real = criterion_MSE(pred_real[0, :], target_real)
        pred_real_l.append(pred_real[0, :].item())

        # Fake loss
        fake_TIR = fake_TIR_buffer.push_and_pop(fake_TIR)
        pred_fake = netD_TIR(fake_TIR.detach())
        loss_D_fake = criterion_MSE(pred_fake[0, :], target_fake)
        pred_fake_l.append(pred_fake[0, :].item())

        # Total loss
        loss_D_TIR = (loss_D_real + loss_D_fake)*0.5
        loss_D_TIR.backward()

        optimizer_D_TIR.step()
        ###################################

        ###### Discriminator RGB ######
        optimizer_D_RGB.zero_grad()

        # Real loss
        pred_real = netD_RGB(real_RGB)
        loss_D_real = criterion_MSE(pred_real[0, :], target_real)
        
        # Fake loss
        fake_RGB = fake_RGB_buffer.push_and_pop(fake_RGB)
        pred_fake = netD_RGB(fake_RGB.detach())
        loss_D_fake = criterion_MSE(pred_fake[0, :], target_fake)

        # Total loss
        loss_D_RGB = (loss_D_real + loss_D_fake)*0.5
        loss_D_RGB.backward()

        optimizer_D_RGB.step()
        ###################################

        # Progress report (http://localhost:8097)
        # logger.log({'loss_G': loss_G, 'loss_G_identity': (loss_identity_A + loss_identity_B), 'loss_G_GAN': (loss_GAN_TIR_2_RGB + loss_GAN_RGB_2_TIR),
        #             'loss_G_cycle': (loss_cycle_ABA + loss_cycle_BAB), 'loss_D': (loss_D_TIR + loss_D_RGB)},
        #             images={'real_TIR': real_TIR, 'real_RGB': real_RGB, 'fake_TIR': fake_TIR, 'fake_RGB': fake_RGB})


    # Update learning rates
    lr_scheduler_G.step()
    lr_scheduler_D_TIR.step()
    lr_scheduler_D_RGB.step()

    # Save models checkpoints
    torch.save(netG_TIR_2_RGB.state_dict(), os.path.join(main_dir,'RGB2TIR/output/p_netG_TIR_2_RGB.pth'))
    torch.save(netG_RGB_2_TIR.state_dict(), os.path.join(main_dir,'RGB2TIR/output/p_netG_RGB_2_TIR.pth'))
    torch.save(netD_TIR.state_dict(), os.path.join(main_dir,'RGB2TIR/output/p_netD_TIR.pth'))
    torch.save(netD_RGB.state_dict(), os.path.join(main_dir,'RGB2TIR/output/p_netD_RGB.pth'))

    # Append mean loss of the last epoch
    mean_Gan_loss.append(statistics.mean(Gan_loss))
    mean_Generate_loss.append(statistics.mean(Generate_loss))
    mean_Recovered_loss.append(statistics.mean(Recovered_loss))
    # mean_Ssim_loss.append(statistics.mean(Ssim_loss))
    # mean_Lpips_f_loss.append(statistics.mean(lpips_fake_loss))
    mean_Vgg_loss.append(statistics.mean(Vgg_loss))

###################################

print('#########################################')
print('summary')
print('=======')

plot.figure(1)
plot.subplot(2, 2, 1)
plot.plot(range(opt.n_epochs), mean_Gan_loss)
plot.title('Mean Gan Loss')
plot.subplot(2, 2, 2)
plot.plot(range(opt.n_epochs), mean_Generate_loss)
plot.title('Mean Generate Loss')
plot.subplot(2, 2, 3)
plot.plot(range(opt.n_epochs), mean_Recovered_loss)
plot.title('Mean Recovered Loss')
plot.subplot(2, 2, 4)
plot.plot(range(opt.n_epochs), mean_Vgg_loss)
plot.title('Mean VGG Loss')

plot.figure(2)
plot.subplot(2, 2, 1)
plot.plot(range(len(pred_fake_l)), pred_fake_l)
plot.title('Pred Fake of TIR Dis')
plot.subplot(2, 2, 2)
plot.plot(range(len(pred_real_l)), pred_real_l)
plot.title('Pred Real of TIR Dis')
# plot.subplot(2, 2, 3)
# plot.plot(range(len(mean_Lpips_f_loss)), mean_Lpips_f_loss)
# plot.title('Mean LPIPS Fake Loss')
plot.show()


